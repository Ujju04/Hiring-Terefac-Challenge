{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-bP6ucjkHf4",
        "outputId": "10189bfb-6f15-4bbd-ae24-bd0a4987e08e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# CONFIGURATION\n",
        "\n",
        "CONFIG = {\n",
        "    \"seed\": 42,\n",
        "    \"model_names\": [\"wide_resnet50_2\", \"resnext50_32x4d\", \"efficientnet_b0\", \"convnext_tiny\"],\n",
        "    \"model_seeds\": [42, 43, 44, 45],\n",
        "    \"batch\": 128,\n",
        "    \"num_epochs\": 120,\n",
        "    \"lr\": 3e-4,\n",
        "    \"wd\": 1e-4,\n",
        "    \"mix_alpha\": 0.8,\n",
        "    \"lbl_smooth\": 0.1,\n",
        "    \"classes\": 10,\n",
        "    \"img_res\": 224,\n",
        "    \"weights_dir\": \"/content/models\",\n",
        "    \"out_dir\": \"/content/results\"\n",
        "}\n",
        "\n",
        "os.makedirs(CONFIG[\"weights_dir\"], exist_ok=True)\n",
        "os.makedirs(CONFIG[\"out_dir\"], exist_ok=True)\n",
        "\n",
        "assert torch.cuda.is_available(), \"CUDA is required.\"\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "# SEED CONTROL\n",
        "def set_global_seed(s):\n",
        "    random.seed(s)\n",
        "    np.random.seed(s)\n",
        "    torch.manual_seed(s)\n",
        "    torch.cuda.manual_seed_all(s)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "set_global_seed(CONFIG[\"seed\"])\n",
        "print(\"Using GPU =>\", torch.cuda.get_device_name(0))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTS\n",
        "\n",
        "import timm\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "NRX6mO8n2H7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MIXUP\n",
        "def mixup_inputs(x, y, strength):\n",
        "    lam = np.random.beta(strength, strength)\n",
        "    idx = torch.randperm(x.size(0), device=x.device)\n",
        "    return lam * x + (1 - lam) * x[idx], y, y[idx], lam\n",
        "\n",
        "def mixup_objective(criterion, outputs, y_a, y_b, lam):\n",
        "    return lam * criterion(outputs, y_a) + (1 - lam) * criterion(outputs, y_b)\n",
        "\n",
        "def compute_accuracy(logits, labels):\n",
        "    return (logits.argmax(dim=1) == labels).float().mean().item()\n",
        "\n",
        "# TRANSFORMS\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.Resize((CONFIG[\"image_size\"], CONFIG[\"image_size\"])),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandAugment(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((CONFIG[\"image_size\"], CONFIG[\"image_size\"])),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "])\n"
      ],
      "metadata": {
        "id": "L8ymURIR2HTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATASET\n",
        "full_train = CIFAR10(\"./data\", train=True, download=True, transform=train_transform)\n",
        "test_set = CIFAR10(\"./data\", train=False, download=True, transform=test_transform)\n",
        "\n",
        "indices = list(range(50000))\n",
        "random.shuffle(indices)\n",
        "\n",
        "train_ids = indices[:40000]\n",
        "val_ids = indices[40000:45000]\n",
        "\n",
        "train_data = Subset(CIFAR10(\"./data\", train=True, transform=train_transform), train_ids)\n",
        "val_data = Subset(CIFAR10(\"./data\", train=True, transform=test_transform), val_ids)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=CONFIG[\"batch\"], shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_data, batch_size=CONFIG[\"batch\"], shuffle=False, num_workers=4)\n",
        "test_loader = DataLoader(test_set, batch_size=CONFIG[\"batch\"], shuffle=False, num_workers=4)\n",
        "\n",
        "print(\"Train:\", len(train_data), \"Val:\", len(val_data), \"Test:\", len(test_set))\n",
        "\n",
        "# MODEL BUILDER\n",
        "def create_model(model_name):\n",
        "    model = timm.create_model(model_name, pretrained=True, num_classes=CONFIG[\"num_classes\"])\n",
        "    return model.to(device)\n"
      ],
      "metadata": {
        "id": "2hnMkR502HGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# TRAINING\n",
        "def train_loop(model, seed, name):\n",
        "    apply_seed(seed)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=CONFIG[\"learning_rate\"], weight_decay=CONFIG[\"weight_decay\"])\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, CONFIG[\"epochs\"])\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=CONFIG[\"label_smoothing\"])\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    best_score = 0.0\n",
        "\n",
        "    for epoch in range(CONFIG[\"epochs\"]):\n",
        "        model.train()\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            mixed_x, y_a, y_b, lam = mixup_inputs(xb, yb, CONFIG[\"mixup_alpha\"])\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with autocast():\n",
        "                preds = model(mixed_x)\n",
        "                loss = mixup_objective(criterion, preds, y_a, y_b, lam)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "        model.eval()\n",
        "        scores = []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                scores.append(compute_accuracy(model(xb), yb))\n",
        "\n",
        "        val_acc = float(np.mean(scores))\n",
        "        scheduler.step()\n",
        "\n",
        "        if val_acc > best_score:\n",
        "            best_score = val_acc\n",
        "            torch.save(model.state_dict(), f\"{CONFIG['model_dir']}/{name}.pth\")\n",
        "\n",
        "        print(name, \"Epoch\", epoch+1, \"ValAcc\", round(val_acc, 4))\n",
        "\n",
        "    return best_score\n"
      ],
      "metadata": {
        "id": "KV6FFVH32RW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# MULTI RUN\n",
        "saved_models = []\n",
        "\n",
        "for mname, s in zip(CONFIG[\"model_names\"], CONFIG[\"run_seeds\"]):\n",
        "    mdl = create_model(mname)\n",
        "    score = train_loop(mdl, s, mname)\n",
        "    saved_models.append(mname)\n",
        "    print(mname, \"BEST VAL:\", score)\n",
        "\n",
        "print(\"CHECKPOINTS:\", saved_models)\n",
        "print(os.listdir(CONFIG[\"model_dir\"]))\n",
        "\n",
        "# ENSEMBLE\n",
        "chosen = [\"wide_resnet50_2\"]\n",
        "\n",
        "def get_test_probs(model):\n",
        "    model.eval()\n",
        "    batch_probs = []\n",
        "    with torch.no_grad():\n",
        "        for xb, _ in test_loader:\n",
        "            xb = xb.to(device)\n",
        "            batch_probs.append(F.softmax(model(xb), dim=1).cpu())\n",
        "    return torch.cat(batch_probs, dim=0)\n",
        "\n",
        "all_outputs = []\n",
        "for name in chosen:\n",
        "    mdl = create_model(name)\n",
        "    mdl.load_state_dict(torch.load(f\"{CONFIG['model_dir']}/{name}.pth\"))\n",
        "    all_outputs.append(get_test_probs(mdl))\n",
        "\n",
        "ensemble_output = torch.stack(all_outputs).mean(dim=0)\n",
        "ensemble_preds = ensemble_output.argmax(dim=1)\n",
        "true_labels = torch.tensor(test_set.targets)\n",
        "test_accuracy = (ensemble_preds == true_labels).float().mean().item()\n",
        "\n",
        "print(\"ENSEMBLE TEST ACC:\", test_accuracy)\n",
        "\n",
        "cm = confusion_matrix(true_labels, ensemble_preds)\n",
        "plt.imshow(cm)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "for c in range(10):\n",
        "    print(c, cm[c, c] / cm[c].sum())\n"
      ],
      "metadata": {
        "id": "a51wRLDh2ROa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# SAVE RESULTS\n",
        "df = pd.DataFrame({\n",
        "    \"index\": range(len(true_labels)),\n",
        "    \"true\": true_labels.numpy(),\n",
        "    \"pred\": ensemble_preds.numpy(),\n",
        "    \"prob\": ensemble_output.max(dim=1).values.numpy()\n",
        "})\n",
        "\n",
        "df.to_csv(f\"{CONFIG['results_dir']}/predictions.csv\", index=False)\n",
        "\n",
        "with open(\"requirements.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join([\n",
        "        \"torch\",\n",
        "        \"torchvision\",\n",
        "        \"timm\",\n",
        "        \"numpy\",\n",
        "        \"pandas\",\n",
        "        \"scikit-learn\",\n",
        "        \"matplotlib\",\n",
        "        \"tqdm\"\n",
        "    ]))\n",
        "\n",
        "print(\"Saved outputs\")"
      ],
      "metadata": {
        "id": "t7kelPkL2RKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zmJAa4jH2b0m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}